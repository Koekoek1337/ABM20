Agent based model of rational agents playing (simplified [[2. Poker Game|poker]])
(see [[Model Layout.canvas|Model Layout]])
## Agents
---
Agents play poker against other agents using their respective strategy. 
This strategy is assigned at startup and may mutate over time

### Observables
---
Extracting data from a model requires definite observables.

**Possible model observables include**:
- Accumulated Wealth per agent
- Agent win rate
- Currently employed strategy per agent
- Strategy win rate
- Accumulated wealth per strategy
- etc.
## Tournament
---
Some selection method is required to have agents interact, obviously.
### Random
Iteratively divide all agents into randomized (possibly weighted?) poker groups and let them each play one game of poker. 

Computationally, this would be the most efficient method, as well as allowing for smaller population sizes.

### Spatial
Distribute all agents spatially over a 2D grid, and making them play against opponents in their (von Neumann) neighborhood. May show development of regional strategies over time,
i.e. emergent behavior.

## Mutation
---
Agent strategies may change over time, which may be controlled through various means. Some examples include:
- **Adaptive**: Let a losing agent take on (part of) the strategy of a winning agent.
- **Evolutionary**: Let an agents strategy be the tuple of pure strategies and respective probabilities. Define some fitness score based on tournament performance. Create offspring of most successful agents using some recombination and/or mutation algorithm and remove some unsuccessful agents. In case of a spatial $[x \times y]$ model, population could be kept at a constant $N < xy$.
- **Random**: Let a losing agent randomly change it's strategy by some purely stochastic means. Likely would take long to converge
- etc.